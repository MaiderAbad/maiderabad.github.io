<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=dark data-auto-appearance=false><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="rgb(255,255,255)"><meta http-equiv=x-ua-compatible content="ie=edge"><title>Enhancing Disease Detection with AI Ensembles &#183; Maider Abad</title><meta name=title content="Enhancing Disease Detection with AI Ensembles &#183; Maider Abad"><meta name=description content="Explore how model ensembles improve the accuracy and generalization of AI for disease detection using chest X-rays."><link rel=canonical href=https://maiderabad.github.io/posts/case-study-scientific-repo/><link type=text/css rel=stylesheet href=/css/main.bundle.min.ec067e3b50018cea2b1506f103813d03e906410fdfe21bcd12eb6bd07303587fb95b1f9e2a62064cb8044eda56fdb566fff31bef7c99fd7e33698ab89634731c.css integrity="sha512-7AZ+O1ABjOorFQbxA4E9A+kGQQ/f4hvNEutr0HMDWH+5Wx+eKmIGTLgETtpW/bVm//Mb73yZ/X4zaYq4ljRzHA=="><script type=text/javascript src=/js/appearance.min.c6198a5ecbc6c7b35a8568d29315f50cf5d775d4461c515a476359767f1a745c245aa83fa96b0c7d83da976cf77481e1fc29537a2391a53ffe69a991638802e6.js integrity="sha512-xhmKXsvGx7NahWjSkxX1DPXXddRGHFFaR2NZdn8adFwkWqg/qWsMfYPal2z3dIHh/ClTeiORpT/+aamRY4gC5g=="></script>
<script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.6d78c827ca7bcbf72056dbf698bf9aeb759a08966686187deb23f5949f73eca5f39b461284900cdfc08e2976d99eb80a8663648de778ba2a83e633ae16dbfc25.js integrity="sha512-bXjIJ8p7y/cgVtv2mL+a63WaCJZmhhh96yP1lJ9z7KXzm0YShJAM38COKXbZnrgKhmNkjed4uiqD5jOuFtv8JQ==" data-copy=Copy data-copied=Copied></script>
<link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:title" content="Enhancing Disease Detection with AI Ensembles"><meta property="og:description" content="Explore how model ensembles improve the accuracy and generalization of AI for disease detection using chest X-rays."><meta property="og:type" content="article"><meta property="og:url" content="https://maiderabad.github.io/posts/case-study-scientific-repo/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-20T00:00:00+00:00"><meta property="article:modified_time" content="2025-01-20T00:00:00+00:00"><meta property="og:site_name" content="Maider Abad"><meta name=twitter:card content="summary"><meta name=twitter:title content="Enhancing Disease Detection with AI Ensembles"><meta name=twitter:description content="Explore how model ensembles improve the accuracy and generalization of AI for disease detection using chest X-rays."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"Enhancing Disease Detection with AI Ensembles","headline":"Enhancing Disease Detection with AI Ensembles","abstract":"Explore how model ensembles improve the accuracy and generalization of AI for disease detection using chest X-rays.","inLanguage":"en","url":"https:\/\/maiderabad.github.io\/posts\/case-study-scientific-repo\/","author":{"@type":"Person","name":"Maider Abad"},"copyrightYear":"2025","dateCreated":"2025-01-20T00:00:00\u002b00:00","datePublished":"2025-01-20T00:00:00\u002b00:00","dateModified":"2025-01-20T00:00:00\u002b00:00","keywords":["AI","model ensemble","medical imaging","chest X-ray","disease detection","transfer learning"],"mainEntityOfPage":"true","wordCount":"874"}]</script><meta name=author content="Maider Abad"><link href=https://github.com/maiderabad rel=me><link href=mailto:maider.abad97d@gmail.com rel=me><link href=https://www.linkedin.com/in/maider-abad/ rel=me></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><header class="py-6 font-semibold text-neutral-900 dark:text-neutral print:hidden sm:py-10"><nav class="flex items-start justify-between sm:items-center"><div class="z-40 flex flex-row items-center"><a href=/ class=mr-2><img src=/logo.png width=40 height=40 class="max-h-[10rem] max-w-[10rem] object-scale-down object-left" alt="Maider Abad"></a></div><label id=menu-button for=menu-controller class=block><input type=checkbox id=menu-controller class=hidden><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative inline-block align-text-bottom icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper class="fixed inset-0 z-30 invisible w-full h-full m-auto overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex flex-col w-full px-6 py-6 mx-auto overflow-visible list-none max-w-7xl ltr:text-right rtl:text-left sm:px-14 sm:py-10 sm:pt-10 md:px-24 lg:px-32"><li class=mb-1><span class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative inline-block align-text-bottom icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class="mb-1 group"><a href=/about/ title=About><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">About</span></a></li><li class="mb-1 group"><a href=/posts/ title=Posts><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">Posts</span></a></li><li class="mb-1 group"><button id=search-button-m0 title="Search (/)">
<span class="transition-colors group-dark:hover:text-primary-400 group-hover:text-primary-600"><span class="relative inline-block align-text-bottom icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></span></button></li></ul></div></label></nav></header><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header class=max-w-prose><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/>Maider Abad</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/posts/>Posts</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/posts/case-study-scientific-repo/>Enhancing Disease Detection with AI Ensembles</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Enhancing Disease Detection with AI Ensembles</h1><div class="mt-8 mb-12 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime="2025-01-20 00:00:00 +0000 UTC">20 January 2025</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">5 mins</span></div><div class="my-1 text-xs leading-relaxed text-neutral-500 dark:text-neutral-400"><a href=/tags/ai/ class="rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">AI</a>
<a href=/tags/model-ensemble/ class="rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">model ensemble</a>
<a href=/tags/medical-imaging/ class="rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">medical imaging</a>
<a href=/tags/chest-x-ray/ class="rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">chest X-ray</a>
<a href=/tags/disease-detection/ class="rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">disease detection</a>
<a href=/tags/transfer-learning/ class="rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">transfer learning</a></div></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first px-0 lg:order-last lg:max-w-xs ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-10"><details open class="mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#the-challenge-generalization-in-medical-image-analysis>The Challenge: Generalization in Medical Image Analysis</a></li><li><a href=#our-solution-ensemble-learning-with-entropy-based-weighting>Our Solution: Ensemble Learning with Entropy-Based Weighting</a><ul><li><a href=#why-use-entropy>Why Use Entropy?</a></li><li><a href=#implementation-details>Implementation Details</a></li></ul></li><li><a href=#results-improved-accuracy-and-robustness>Results: Improved Accuracy and Robustness</a><ul><li><a href=#internal-validation>Internal Validation</a></li><li><a href=#external-validation>External Validation</a></li></ul></li><li><a href=#key-insights-and-broader-applications>Key Insights and Broader Applications</a><ul><li><a href=#1-generalization-to-diverse-datasets>1. <strong>Generalization to Diverse Datasets</strong></a></li><li><a href=#2-potential-for-broader-use>2. <strong>Potential for Broader Use</strong></a></li><li><a href=#3-scalability-and-flexibility>3. <strong>Scalability and Flexibility</strong></a></li></ul></li><li><a href=#challenges-and-future-directions>Challenges and Future Directions</a><ul><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></div></details></div></div><div class="min-w-0 min-h-0 max-w-prose grow"><div class="lead !mb-9 text-xl"><p>Advancements in artificial intelligence (AI) have revolutionized medical diagnostics, providing tools that promise both speed and accuracy. In one of my recent studies, published in <em>Scientific Reports</em>, I explored how ensemble learning techniques can improve the generalization of pre-trained convolutional neural networks (CNNs) for disease detection using chest X-ray images. This post delves deeper into the challenges we addressed, our methodology, key findings, and the broader implications of this research.</p><p>Refer to the <a href=https://doi.org/10.1038/s41598-024-56171-6 target=_blank rel="noreferrer noopener">full article</a> for more details.</p></div><hr><h2 id=the-challenge-generalization-in-medical-image-analysis class="relative group">The Challenge: Generalization in Medical Image Analysis <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#the-challenge-generalization-in-medical-image-analysis aria-label=Anchor>#</a></span></h2><p>Medical imaging models often exhibit strong performance during internal testing but struggle when applied to external datasets—a phenomenon known as the &ldquo;generalization gap.&rdquo; This challenge arises primarily from two factors:</p><ol><li><strong>Limited Data Diversity:</strong> Most public medical datasets lack sufficient diversity to represent the variability in imaging techniques, equipment, and patient demographics across different healthcare facilities.</li><li><strong>Bias in Model Training:</strong> Models tend to overfit to the specific characteristics of their training datasets, which limits their ability to handle unseen data effectively.</li></ol><p>In our study, we focused on COVID-19 detection using chest X-ray images. We evaluated three widely-used pre-trained CNN architectures—<strong>ResNet50</strong>, <strong>DenseNet121</strong>, and <strong>Inception-ResNet-v2</strong>—to identify their strengths and weaknesses. While these models achieved impressive results during internal validation, their performance declined significantly during external validation. For instance, DenseNet121 reached <strong>96.71% accuracy</strong> in internal testing but dropped to just <strong>61.49% accuracy</strong> when applied to external datasets.</p><p>This stark contrast underscores the critical need for robust methodologies that ensure consistent performance across diverse datasets.</p><hr><h2 id=our-solution-ensemble-learning-with-entropy-based-weighting class="relative group">Our Solution: Ensemble Learning with Entropy-Based Weighting <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#our-solution-ensemble-learning-with-entropy-based-weighting aria-label=Anchor>#</a></span></h2><p>To address the generalization gap, we developed an ensemble learning approach that combines predictions from multiple models. Unlike traditional ensembling techniques (e.g., simple averaging or majority voting), our method employs <strong>uncertainty-based weighting</strong> to assign dynamic weights to each model&rsquo;s output based on its entropy.</p><h3 id=why-use-entropy class="relative group">Why Use Entropy? <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-use-entropy aria-label=Anchor>#</a></span></h3><p>Entropy measures the uncertainty of a model&rsquo;s prediction. A high entropy value indicates greater uncertainty, whereas a low entropy value signifies confidence. By assigning higher weights to models with lower entropy, our approach prioritizes more reliable predictions, leading to improved overall accuracy.</p><h3 id=implementation-details class="relative group">Implementation Details <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#implementation-details aria-label=Anchor>#</a></span></h3><ol><li><strong>Model Selection:</strong> We used three pre-trained CNN architectures—ResNet50, DenseNet121, and Inception-ResNet-v2—trained on the ImageNet dataset and fine-tuned for COVID-19 detection.</li><li><strong>Data Processing:</strong><ul><li>Datasets included over <strong>26,000 images</strong> from multiple sources, with a balanced distribution of COVID-19 positive and negative cases.</li><li>Images were resized to <strong>256x256 pixels</strong> and normalized for consistent preprocessing.</li></ul></li><li><strong>Training Procedure:</strong><ul><li>Transfer learning was applied, freezing pre-trained layers and adding custom dense layers with dropout regularization to prevent overfitting.</li><li>The models were trained for <strong>50 epochs</strong> using the Adam optimizer with a learning rate of <strong>$10^{-4}$</strong>.</li></ul></li><li><strong>Ensemble Methodology:</strong><ul><li>Entropy values were calculated for each model&rsquo;s prediction.</li><li>Weights were assigned to each model output using an exponential function of entropy.</li><li>Final predictions were generated by aggregating the weighted outputs of all three models.</li></ul></li></ol><hr><h2 id=results-improved-accuracy-and-robustness class="relative group">Results: Improved Accuracy and Robustness <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#results-improved-accuracy-and-robustness aria-label=Anchor>#</a></span></h2><p>The ensemble method demonstrated remarkable improvements over individual models, particularly in external validation scenarios.</p><h3 id=internal-validation class="relative group">Internal Validation <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#internal-validation aria-label=Anchor>#</a></span></h3><ul><li><strong>Accuracy:</strong> <strong>97.38%</strong> (compared to 96.71% for DenseNet121 alone)</li><li><strong>Sensitivity:</strong> <strong>96.45%</strong></li><li><strong>Specificity:</strong> <strong>98.26%</strong></li></ul><h3 id=external-validation class="relative group">External Validation <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#external-validation aria-label=Anchor>#</a></span></h3><ul><li><strong>Accuracy:</strong> <strong>81.16%</strong> (compared to 78.38% for ResNet50)</li><li><strong>Sensitivity:</strong> <strong>80.97%</strong></li><li><strong>Specificity:</strong> <strong>81.31%</strong></li></ul><p>These results indicate that the ensemble model not only outperforms individual networks but also achieves a balanced performance in identifying both COVID-19 positive and negative cases.</p><hr><h2 id=key-insights-and-broader-applications class="relative group">Key Insights and Broader Applications <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-insights-and-broader-applications aria-label=Anchor>#</a></span></h2><h3 id=1-generalization-to-diverse-datasets class="relative group">1. <strong>Generalization to Diverse Datasets</strong> <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#1-generalization-to-diverse-datasets aria-label=Anchor>#</a></span></h3><p>Our results emphasize the importance of incorporating data from multiple sources during both training and validation. This approach ensures that models are exposed to a wider range of imaging variations, improving their adaptability to new datasets.</p><h3 id=2-potential-for-broader-use class="relative group">2. <strong>Potential for Broader Use</strong> <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#2-potential-for-broader-use aria-label=Anchor>#</a></span></h3><p>While our study focused on COVID-19 detection, the ensemble methodology is adaptable to other medical imaging challenges, such as pneumonia classification or cancer detection. The underlying principle—leveraging model diversity to enhance performance—applies across domains.</p><h3 id=3-scalability-and-flexibility class="relative group">3. <strong>Scalability and Flexibility</strong> <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#3-scalability-and-flexibility aria-label=Anchor>#</a></span></h3><p>The ensemble framework can be scaled to include additional models or modalities, such as CT scans or MRI images. This flexibility makes it a versatile tool for various diagnostic tasks.</p><hr><h2 id=challenges-and-future-directions class="relative group">Challenges and Future Directions <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#challenges-and-future-directions aria-label=Anchor>#</a></span></h2><p>Despite its promise, our approach faces several limitations:</p><ol><li><strong>Lack of Metadata:</strong> Many public datasets lack demographic and clinical metadata, such as patient age or disease severity. Integrating such metadata could improve model interpretability and performance.</li><li><strong>Complexity of Mild Cases:</strong> The ensemble struggled to accurately classify mild COVID-19 cases, highlighting the need for more refined weighting mechanisms.</li><li><strong>External Validation Diversity:</strong> Although our study included multiple external datasets, further testing on a wider range of sources would strengthen the generalizability of the results.</li></ol><h3 id=future-research class="relative group">Future Research <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#future-research aria-label=Anchor>#</a></span></h3><ul><li><strong>Incorporating Metadata:</strong> Using demographic and clinical data to refine predictions and identify biases.</li><li><strong>Exploring Advanced Techniques:</strong> Investigating alternative ensemble methods, such as attention-based weighting.</li><li><strong>Expanding Applications:</strong> Applying the methodology to other diseases and imaging modalities.</li></ul><hr><h2 id=conclusion class="relative group">Conclusion <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#conclusion aria-label=Anchor>#</a></span></h2><p>Our research demonstrates the transformative potential of ensemble learning for medical diagnostics. By addressing the generalization gap, this methodology offers a robust, scalable, and clinically viable solution for disease detection using AI. As we move forward, continued innovation and interdisciplinary collaboration will be key to realizing the full potential of AI in healthcare.</p><hr><p>What are your thoughts on this approach? Could ensemble methods play a pivotal role in improving real-world AI applications? Share your insights in the comments below!</p></div></section><footer class="pt-8 max-w-prose print:hidden"><div class=flex><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Maider Abad</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://github.com/maiderabad target=_blank aria-label=Github rel="me noopener noreferrer"><span class="relative inline-block align-text-bottom icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></a><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=mailto:maider.abad97d@gmail.com target=_blank aria-label=Email rel="me noopener noreferrer"><span class="relative inline-block align-text-bottom icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a><a class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400" style=will-change:transform href=https://www.linkedin.com/in/maider-abad/ target=_blank aria-label=Linkedin rel="me noopener noreferrer"><span class="relative inline-block align-text-bottom icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg></span></a></div></div></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><div class=comments><script>var getTheme=localStorage&&localStorage.getItem("appearance"),getTheme=getTheme??"dark";let theme=getTheme==="dark"?"photon-dark":"github-light",s=document.createElement("script");s.src="https://utteranc.es/client.js",s.setAttribute("repo","cgutierr-zgz/cgutierr-zgz.github.io"),s.setAttribute("issue-term","pathname"),s.setAttribute("theme",theme),s.setAttribute("crossorigin","anonymous"),s.setAttribute("async",""),document.querySelector("div.comments").innerHTML="",document.querySelector("div.comments").appendChild(s),window.addEventListener("DOMContentLoaded",e=>{const t=document.getElementById("appearance-switcher-0");t&&t.addEventListener("click",()=>{let e=document.documentElement.classList.contains("dark")?"photon-dark":"github-light";const t={type:"set-theme",theme:e},n=document.querySelector(".utterances-frame");n.contentWindow.postMessage(t,"https://utteranc.es")})})</script></div></div></div></footer></article><div class="pointer-events-none absolute top-[100vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer class="py-10 print:hidden"><div class="flex items-center justify-between"><div><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Maider Abad</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://git.io/hugo-congo target=_blank rel="noopener noreferrer">Congo</a></p></div><div class="ltr:mr-14 rtl:ml-14 cursor-pointer text-sm text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"><button id=appearance-switcher-0 type=button aria-label="appearance switcher"><div class="flex items-center justify-center w-12 h-12 dark:hidden" title="Switch to dark appearance"><span class="relative inline-block align-text-bottom icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden w-12 h-12 dark:flex" title="Switch to light appearance"><span class="relative inline-block align-text-bottom icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div></footer><div id=search-wrapper class="invisible fixed inset-0 z-50 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://maiderabad.github.io/><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative inline-block align-text-bottom icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative inline-block align-text-bottom icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>